{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day100_transfer_learning_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6sfCEt-7RADT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 作業\n",
        "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
        "\n",
        "\n",
        "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
        "\n",
        "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
      ]
    },
    {
      "metadata": {
        "id": "UIM5IHGuRADU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6633
        },
        "outputId": "70a6e15e-a0ef-4fce-d9dd-42f71fc5d1eb"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 影像大小\n",
        "IMAGE_SIZE = (32, 32)\n",
        "\n",
        "# 影像類別數\n",
        "num_classes = 10\n",
        "\n",
        "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
        "batch_size = 128\n",
        "\n",
        "# 凍結網路層數\n",
        "FREEZE_LAYERS = 2\n",
        "\n",
        "# Epoch 數\n",
        "epochs = 100\n",
        "\n",
        "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   channel_shift_range=10,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
        "# 捨棄 ResNet50 頂層的 fully connected layers\n",
        "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
        "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "x = net.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# 增加 DropOut layer\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
        "output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
        "\n",
        "net_final = Model(inputs=net.input, outputs=output_layer)\n",
        "\n",
        "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
        "net_final.compile(optimizer=Adam(lr=1e-5),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 輸出整個網路結構\n",
        "print(net_final.summary())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalizationV1) (None, 16, 16, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 256)    0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 4, 4, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 10)           20490       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wPJ82aepRADg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fa0d122-d153-4eb2-f098-32204b5cedf8"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tb1kw3YSRADj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6d0ce458-1130-4ccf-faf5-a55e8ddc18ed"
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "beZ63-AORADm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5188
        },
        "outputId": "4dc8e0d6-9de2-4d45-a59f-7c6320dc69af"
      },
      "cell_type": "code",
      "source": [
        "history = net_final.fit_generator(\n",
        "        train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "        steps_per_epoch=int(len(x_train)/batch_size),\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        validation_data=(x_test, y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 3s 342us/sample - loss: 2.2843 - acc: 0.1976\n",
            "391/391 [==============================] - 56s 144ms/step - loss: 3.3072 - acc: 0.1305 - val_loss: 2.2880 - val_acc: 0.1976\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 2.0611 - acc: 0.3129\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 2.3286 - acc: 0.1988 - val_loss: 2.0603 - val_acc: 0.3129\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 1.8677 - acc: 0.3936\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 2.1774 - acc: 0.2604 - val_loss: 1.8693 - val_acc: 0.3936\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 1.6988 - acc: 0.4523\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 2.0283 - acc: 0.3199 - val_loss: 1.7099 - val_acc: 0.4523\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 1.5085 - acc: 0.5009\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.8619 - acc: 0.3831 - val_loss: 1.5211 - val_acc: 0.5009\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 1.3845 - acc: 0.5414\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.7196 - acc: 0.4333 - val_loss: 1.3965 - val_acc: 0.5414\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 2s 246us/sample - loss: 1.2855 - acc: 0.5680\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.6104 - acc: 0.4706 - val_loss: 1.2939 - val_acc: 0.5680\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 1.2473 - acc: 0.5910\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 1.5184 - acc: 0.4998 - val_loss: 1.2594 - val_acc: 0.5910\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 2s 229us/sample - loss: 1.1827 - acc: 0.6079\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 1.4480 - acc: 0.5277 - val_loss: 1.1852 - val_acc: 0.6079\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 1.1262 - acc: 0.6235\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.3826 - acc: 0.5513 - val_loss: 1.1272 - val_acc: 0.6235\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 1.0928 - acc: 0.6378\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.3286 - acc: 0.5652 - val_loss: 1.0936 - val_acc: 0.6378\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 1.0442 - acc: 0.6506\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.2641 - acc: 0.5853 - val_loss: 1.0444 - val_acc: 0.6506\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 1.0204 - acc: 0.6581\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2291 - acc: 0.5944 - val_loss: 1.0206 - val_acc: 0.6581\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 2s 222us/sample - loss: 1.0018 - acc: 0.6681\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.1865 - acc: 0.6050 - val_loss: 1.0017 - val_acc: 0.6681\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.9609 - acc: 0.6776\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.1327 - acc: 0.6170 - val_loss: 0.9608 - val_acc: 0.6776\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.9393 - acc: 0.6848\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 1.0930 - acc: 0.6283 - val_loss: 0.9393 - val_acc: 0.6848\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.9244 - acc: 0.6912\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0554 - acc: 0.6409 - val_loss: 0.9247 - val_acc: 0.6912\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 2s 235us/sample - loss: 0.8782 - acc: 0.7065\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0318 - acc: 0.6478 - val_loss: 0.8789 - val_acc: 0.7065\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.8680 - acc: 0.7065\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 1.0070 - acc: 0.6530 - val_loss: 0.8685 - val_acc: 0.7065\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 2s 245us/sample - loss: 0.8771 - acc: 0.7059\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.9868 - acc: 0.6586 - val_loss: 0.8772 - val_acc: 0.7059\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.8314 - acc: 0.7176\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9641 - acc: 0.6665 - val_loss: 0.8322 - val_acc: 0.7176\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.8203 - acc: 0.7217\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9438 - acc: 0.6754 - val_loss: 0.8215 - val_acc: 0.7217\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.8113 - acc: 0.7258\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.9257 - acc: 0.6802 - val_loss: 0.8114 - val_acc: 0.7258\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 0.7748 - acc: 0.7347\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9157 - acc: 0.6853 - val_loss: 0.7758 - val_acc: 0.7347\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 2s 222us/sample - loss: 0.7851 - acc: 0.7350\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.8962 - acc: 0.6919 - val_loss: 0.7857 - val_acc: 0.7350\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.7607 - acc: 0.7406\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.8791 - acc: 0.6969 - val_loss: 0.7622 - val_acc: 0.7406\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.7615 - acc: 0.7407\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.8628 - acc: 0.7007 - val_loss: 0.7655 - val_acc: 0.7407\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.7424 - acc: 0.7443\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.8473 - acc: 0.7064 - val_loss: 0.7430 - val_acc: 0.7443\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.7263 - acc: 0.7510\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.8378 - acc: 0.7113 - val_loss: 0.7271 - val_acc: 0.7510\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.7236 - acc: 0.7517\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.8333 - acc: 0.7133 - val_loss: 0.7263 - val_acc: 0.7517\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 2s 246us/sample - loss: 0.7155 - acc: 0.7553\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.8160 - acc: 0.7178 - val_loss: 0.7196 - val_acc: 0.7553\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.7185 - acc: 0.7561\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.8028 - acc: 0.7214 - val_loss: 0.7243 - val_acc: 0.7561\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 2s 229us/sample - loss: 0.7122 - acc: 0.7557\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.7933 - acc: 0.7256 - val_loss: 0.7160 - val_acc: 0.7557\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.7059 - acc: 0.7621\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.7851 - acc: 0.7302 - val_loss: 0.7191 - val_acc: 0.7621\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.6792 - acc: 0.7667\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.7709 - acc: 0.7333 - val_loss: 0.6877 - val_acc: 0.7667\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.6977 - acc: 0.7654\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.7624 - acc: 0.7354 - val_loss: 0.6997 - val_acc: 0.7654\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.6773 - acc: 0.7682\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.7628 - acc: 0.7354 - val_loss: 0.6797 - val_acc: 0.7682\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.6994 - acc: 0.7667\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.7442 - acc: 0.7414 - val_loss: 0.7016 - val_acc: 0.7667\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6855 - acc: 0.7684\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 0.7400 - acc: 0.7426 - val_loss: 0.6876 - val_acc: 0.7684\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6561 - acc: 0.7782\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.7287 - acc: 0.7477 - val_loss: 0.6635 - val_acc: 0.7782\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6686 - acc: 0.7736\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.7213 - acc: 0.7500 - val_loss: 0.6798 - val_acc: 0.7736\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 0.6652 - acc: 0.7727\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.7153 - acc: 0.7525 - val_loss: 0.6672 - val_acc: 0.7727\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.6474 - acc: 0.7781\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.7119 - acc: 0.7535 - val_loss: 0.6500 - val_acc: 0.7781\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 2s 244us/sample - loss: 0.6457 - acc: 0.7802\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.6986 - acc: 0.7588 - val_loss: 0.6597 - val_acc: 0.7802\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6534 - acc: 0.7793\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.6979 - acc: 0.7583 - val_loss: 0.6672 - val_acc: 0.7793\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 2s 244us/sample - loss: 0.6630 - acc: 0.7814\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.6873 - acc: 0.7610 - val_loss: 0.6766 - val_acc: 0.7814\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.6376 - acc: 0.7837\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.6783 - acc: 0.7640 - val_loss: 0.6451 - val_acc: 0.7837\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 2s 222us/sample - loss: 0.6431 - acc: 0.7820\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.6796 - acc: 0.7635 - val_loss: 0.6507 - val_acc: 0.7820\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 3s 284us/sample - loss: 0.6371 - acc: 0.7857\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.6684 - acc: 0.7674 - val_loss: 0.6371 - val_acc: 0.7857\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.6162 - acc: 0.7905\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.6642 - acc: 0.7684 - val_loss: 0.6190 - val_acc: 0.7905\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.6214 - acc: 0.7890\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.6559 - acc: 0.7715 - val_loss: 0.6345 - val_acc: 0.7890\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6349 - acc: 0.7890\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.6503 - acc: 0.7741 - val_loss: 0.6487 - val_acc: 0.7890\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 2s 238us/sample - loss: 0.6221 - acc: 0.7904\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.6415 - acc: 0.7769 - val_loss: 0.6350 - val_acc: 0.7904\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.6117 - acc: 0.7935\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 0.6338 - acc: 0.7791 - val_loss: 0.6132 - val_acc: 0.7935\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 2s 229us/sample - loss: 0.6156 - acc: 0.7942\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.6327 - acc: 0.7810 - val_loss: 0.6215 - val_acc: 0.7942\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.6173 - acc: 0.7914\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.6344 - acc: 0.7793 - val_loss: 0.6260 - val_acc: 0.7914\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 2s 245us/sample - loss: 0.6003 - acc: 0.7987\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.6259 - acc: 0.7830 - val_loss: 0.6115 - val_acc: 0.7987\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.6029 - acc: 0.7976\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.6175 - acc: 0.7840 - val_loss: 0.6051 - val_acc: 0.7976\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.6020 - acc: 0.7985\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.6083 - acc: 0.7880 - val_loss: 0.6040 - val_acc: 0.7985\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.6234 - acc: 0.7950\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.6112 - acc: 0.7887 - val_loss: 0.6301 - val_acc: 0.7950\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5942 - acc: 0.8021\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 0.6048 - acc: 0.7893 - val_loss: 0.5972 - val_acc: 0.8021\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5995 - acc: 0.8036\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5965 - acc: 0.7911 - val_loss: 0.6032 - val_acc: 0.8036\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5975 - acc: 0.8049\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.5980 - acc: 0.7949 - val_loss: 0.5992 - val_acc: 0.8049\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6057 - acc: 0.8039\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5932 - acc: 0.7954 - val_loss: 0.6081 - val_acc: 0.8039\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.6147 - acc: 0.7979\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.5818 - acc: 0.7971 - val_loss: 0.6172 - val_acc: 0.7979\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 2s 222us/sample - loss: 0.5925 - acc: 0.8066\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5798 - acc: 0.7978 - val_loss: 0.5952 - val_acc: 0.8066\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5876 - acc: 0.8049\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.5735 - acc: 0.8006 - val_loss: 0.5906 - val_acc: 0.8049\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 2s 244us/sample - loss: 0.5894 - acc: 0.8037\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.5796 - acc: 0.7983 - val_loss: 0.5924 - val_acc: 0.8037\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.5905 - acc: 0.8077\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.5672 - acc: 0.8003 - val_loss: 0.5936 - val_acc: 0.8077\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 2s 242us/sample - loss: 0.5886 - acc: 0.8057\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.5647 - acc: 0.8005 - val_loss: 0.5917 - val_acc: 0.8057\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 2s 222us/sample - loss: 0.5744 - acc: 0.8110\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5588 - acc: 0.8074 - val_loss: 0.5777 - val_acc: 0.8110\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.5949 - acc: 0.8035\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.5532 - acc: 0.8072 - val_loss: 0.5973 - val_acc: 0.8035\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.5867 - acc: 0.8047\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5483 - acc: 0.8091 - val_loss: 0.5894 - val_acc: 0.8047\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5731 - acc: 0.8101\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.5485 - acc: 0.8093 - val_loss: 0.5760 - val_acc: 0.8101\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.5786 - acc: 0.8093\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.5460 - acc: 0.8077 - val_loss: 0.5810 - val_acc: 0.8093\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.5692 - acc: 0.8089\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.5369 - acc: 0.8138 - val_loss: 0.5719 - val_acc: 0.8089\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 2s 246us/sample - loss: 0.5703 - acc: 0.8118\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.5367 - acc: 0.8130 - val_loss: 0.5729 - val_acc: 0.8118\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 2s 224us/sample - loss: 0.5784 - acc: 0.8089\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 0.5329 - acc: 0.8117 - val_loss: 0.5814 - val_acc: 0.8089\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.5739 - acc: 0.8117\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5298 - acc: 0.8164 - val_loss: 0.5824 - val_acc: 0.8117\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.5582 - acc: 0.8138\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.5211 - acc: 0.8167 - val_loss: 0.5618 - val_acc: 0.8138\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 2s 231us/sample - loss: 0.5693 - acc: 0.8143\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.5232 - acc: 0.8164 - val_loss: 0.5724 - val_acc: 0.8143\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 2s 223us/sample - loss: 0.5837 - acc: 0.8112\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.5211 - acc: 0.8175 - val_loss: 0.5919 - val_acc: 0.8112\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 2s 243us/sample - loss: 0.5683 - acc: 0.8147\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.5129 - acc: 0.8225 - val_loss: 0.5721 - val_acc: 0.8147\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 0.5712 - acc: 0.8151\n",
            "391/391 [==============================] - 48s 124ms/step - loss: 0.5076 - acc: 0.8205 - val_loss: 0.5745 - val_acc: 0.8151\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 2s 229us/sample - loss: 0.5728 - acc: 0.8155\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.5036 - acc: 0.8242 - val_loss: 0.5769 - val_acc: 0.8155\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.5671 - acc: 0.8154\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.5036 - acc: 0.8235 - val_loss: 0.5708 - val_acc: 0.8154\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 0.5576 - acc: 0.8167\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.5031 - acc: 0.8254 - val_loss: 0.5601 - val_acc: 0.8167\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.5732 - acc: 0.8135\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.4961 - acc: 0.8273 - val_loss: 0.5759 - val_acc: 0.8135\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 0.5609 - acc: 0.8179\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 0.4881 - acc: 0.8285 - val_loss: 0.5641 - val_acc: 0.8179\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5780 - acc: 0.8162\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.4929 - acc: 0.8279 - val_loss: 0.5833 - val_acc: 0.8162\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 2s 227us/sample - loss: 0.5709 - acc: 0.8133\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 0.4906 - acc: 0.8282 - val_loss: 0.5742 - val_acc: 0.8133\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 3s 251us/sample - loss: 0.5620 - acc: 0.8177\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.4858 - acc: 0.8312 - val_loss: 0.5648 - val_acc: 0.8177\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5631 - acc: 0.8199\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 0.4795 - acc: 0.8343 - val_loss: 0.5669 - val_acc: 0.8199\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 2s 235us/sample - loss: 0.5659 - acc: 0.8151\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.4796 - acc: 0.8312 - val_loss: 0.5693 - val_acc: 0.8151\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.5636 - acc: 0.8175\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.4785 - acc: 0.8318 - val_loss: 0.5673 - val_acc: 0.8175\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 2s 228us/sample - loss: 0.5669 - acc: 0.8205\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 0.4690 - acc: 0.8343 - val_loss: 0.5706 - val_acc: 0.8205\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.5512 - acc: 0.8205\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.4727 - acc: 0.8336 - val_loss: 0.5548 - val_acc: 0.8205\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5619 - acc: 0.8184\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.4669 - acc: 0.8373 - val_loss: 0.5635 - val_acc: 0.8184\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 2s 226us/sample - loss: 0.5604 - acc: 0.8213\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 0.4605 - acc: 0.8391 - val_loss: 0.5627 - val_acc: 0.8213\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 2s 225us/sample - loss: 0.5554 - acc: 0.8219\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.4617 - acc: 0.8398 - val_loss: 0.5588 - val_acc: 0.8219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kaOk6BybX1Xe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6a0e4629-22ec-4a9f-b387-cc8eadd3f3ab"
      },
      "cell_type": "code",
      "source": [
        "score = net_final.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5554125337600708\n",
            "Test accuracy: 0.8219\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}